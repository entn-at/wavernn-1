{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavernn\n",
    "\n",
    "### Neural Synthesizer has been proven to be way powerful than statistical synthesize, but there has been core issue of performance, this implementaion is based on a paper which helps in reducing that performance requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "WmUJhEREa0Z-"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#matplotlib inline provides support to render plots directly in the jupyter notebook, it gets handy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This model has been completely developed upon tensorflow, it uses numpy and math to calculate different mathematical functions.\n",
    "My initial testing includes mathematical functions due to computation overhead of sound files.\n",
    "\n",
    "function of clear_output is to clear the consoles, comes handy\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper params have been defined in the central location for easy access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameters={\n",
    "    \"length_of_wave\":100000, # Total length of sine wave // trained on sine wave to better analyse whole algorithm\n",
    "    \"sample_rate\":16000, # number of samples in a second\n",
    "    \"batch_size\":1, # number of batches\n",
    "    \"max_sequence_length\":100, # maximum number of sequential steps, this network can generate (should be 1k but it is computationally costly and requires much more training time)\n",
    "    \"number_input_in_each_instant\":{\n",
    "        \"coarse\":2, # to incorporate [c(t-1),f(t-1)]\n",
    "        \"fine\":3 # to incorporate [c(t-1),f(t-1),c(t)]\n",
    "    },\n",
    "    \"number_of_the_rnn_cells\":896, #Defined in the paper\n",
    "    \"depth_of_relu_networks\":896, #Defined in the paper\n",
    "    \"softmax_probability\":256, #By using 256, we can level the output in terms of probability, thus better ways to analyse\n",
    "    \"number_of_layers_in_rnns\":2, #Needs to find best layer size\n",
    "    \"new_sequences\": 10, # while generating how many new sequence it should generate\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This block is used to generate the input samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ylDPyznRa0aD"
   },
   "outputs": [],
   "source": [
    "# Next line is used to generate sine wave\n",
    "function = np.sin(np.arange(hyper_parameters['length_of_wave']) * 2 * np.pi /hyper_parameters['sample_rate']).astype(np.float32)\n",
    "\n",
    "# Clipping Extra output, so that it can range between [0, 2^16] for label classication\n",
    "function=np.clip(function * math.pow(2,15), -math.pow(2,15), math.pow(2,15) - 1).astype(np.int16)+2**15\n",
    "\n",
    "# Calculating coarse and fine parts of the wave\n",
    "coarse_part=function//256\n",
    "fine_part=function%256\n",
    "\n",
    "# Input and Output vector of both types respectively\n",
    "X={\n",
    "    \"coarse\":list(),\n",
    "    \"fine\":list()\n",
    "}\n",
    "y={\n",
    "    \"coarse\":list(),\n",
    "    \"fine\":list()\n",
    "}\n",
    "\n",
    "# Converting sine wave data into feature sets as described in the paper\n",
    "for e in range(1,hyper_parameters['length_of_wave']-1):\n",
    "    # X has been divided by 256 to normalize the input data\n",
    "    # while y hasnt been because we will be making y as one hot encoding vector.\n",
    "    X['coarse'].append([coarse_part[e-1]/256.0,coarse_part[e-1]/256.0])\n",
    "    X['fine'].append([coarse_part[e-1]/256.0,fine_part[e-1]/256.0,coarse_part[e]/256.0])\n",
    "    y['coarse'].append([coarse_part[e]])\n",
    "    y['fine'].append([fine_part[e]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of the input function for illustrative purposes\n",
    "plt.plot(function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 978,
     "status": "ok",
     "timestamp": 1528986134163,
     "user": {
      "displayName": "Karan Dhingra",
      "photoUrl": "//lh6.googleusercontent.com/-5rw5kj6_qp4/AAAAAAAAAAI/AAAAAAAALMA/vP4yaQCADJA/s50-c-k-no/photo.jpg",
      "userId": "112729077975125827597"
     },
     "user_tz": -330
    },
    "id": "6KIipSJpa0aN",
    "outputId": "d8db46b2-c32d-44c8-d94f-bf922a357242"
   },
   "outputs": [],
   "source": [
    "# In the same way, coarse has been plotted to better understand the data\n",
    "plt.plot(X['coarse'][30000:31000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "d5NCwMoUa0aP"
   },
   "outputs": [],
   "source": [
    "# In the same way, fine has been plotted to better understand the data\n",
    "# green lines belong to c(t), while orange to f(t)\n",
    "plt.plot(X['fine'][30000:31000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This block contains some manipulation over tensors to ease the architecture defined in the next block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_from_deep(type_of_input):\n",
    "    # In the next line, we calculate index of an element whose value is maximum\n",
    "    probablistic_best_level=tf.nn.top_k(tf.nn.softmax(deep_layer[type_of_input]),1)[1]\n",
    "    # Used to normalize the output from the neural netwoks\n",
    "    return tf.divide(probablistic_best_level,tf.constant(256))\n",
    "\n",
    "def get_deep_layer(type_of_input):\n",
    "    # Next line is used to change the shape of the output function, both of these lines denotes a fully connected neural network\n",
    "    hidden_output=tf.nn.relu(tf.matmul(last_time_instant[type_of_input], weights['deep_layer'][type_of_input]) + bias['deep_layer'][type_of_input])\n",
    "    return tf.matmul(hidden_output, weights['output_layer'][type_of_input]) + bias['output_layer'][type_of_input]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture of the Wavernn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "dTI4g9zza0af",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_types=[\"coarse\",\"fine\"]\n",
    "\n",
    "tf_input={\n",
    "    \"X\":{},\n",
    "    \"y\":{}\n",
    "}\n",
    "\n",
    "\n",
    "number_of_the_rnn_cells=896\n",
    "depth_of_relu_networks=896\n",
    "softmax_probability=256\n",
    "number_of_layers_in_rnns=2\n",
    "\n",
    "\n",
    "# 4 different types of weights and biased have been used to make the connection more viable and to transfer shape from `X1->X2`\n",
    "weights={\n",
    "    \"deep_layer\":{\n",
    "       \"coarse\":tf.Variable(tf.random_normal(shape=[number_of_the_rnn_cells,depth_of_relu_networks]),dtype=tf.float32),\n",
    "       \"fine\":tf.Variable(tf.random_normal(shape=[number_of_the_rnn_cells,depth_of_relu_networks]),dtype=tf.float32)\n",
    "    },\n",
    "    \"output_layer\":{\n",
    "        \"coarse\":tf.Variable(tf.random_normal(shape=[depth_of_relu_networks,softmax_probability]),dtype=tf.float32),\n",
    "        \"fine\":tf.Variable(tf.random_normal(shape=[depth_of_relu_networks,softmax_probability]),dtype=tf.float32)\n",
    "    }\n",
    "}\n",
    "bias={\n",
    "    \"deep_layer\":{\n",
    "       \"coarse\":tf.Variable(tf.random_normal(shape=[depth_of_relu_networks]),dtype=tf.float32),\n",
    "       \"fine\":tf.Variable(tf.random_normal(shape=[depth_of_relu_networks]),dtype=tf.float32)\n",
    "    },\n",
    "    \"output_layer\":{\n",
    "        \"coarse\":tf.Variable(tf.random_normal(shape=[softmax_probability]),dtype=tf.float32),\n",
    "        \"fine\":tf.Variable(tf.random_normal(shape=[softmax_probability]),dtype=tf.float32)\n",
    "    }\n",
    "}\n",
    "\n",
    "# All of the next code lines is to reprepresent whole architecture in terms of the tensors\n",
    "\n",
    "#gru cell, gru is just like RNN cell (more powerfull) though this parameters contains layer of the input.\n",
    "gru_cells={}\n",
    "# densed_Cell is used to make layers of rnn_cell, juse like a single one\n",
    "densed_gru_cells={}\n",
    "# raw_time_outputs gives raw outputs from gru tensors.\n",
    "raw_time_outputs={}\n",
    "# In last_time_instant, transposed is perform so that output only contains last iteration\n",
    "last_time_instant={}\n",
    "# deep_layer is intialized when we perform an relu operation over linear transformation.\n",
    "deep_layer={}\n",
    "# output layer takes output directly from relu and does another linear transformation.\n",
    "output_layer={}\n",
    "# to store costs of of the different batch entries\n",
    "different_costs={}\n",
    "# Adam optimizer, need to tune its hyperpara\n",
    "optimizer={}\n",
    "\n",
    "# this loop performs manager each of the tensors\n",
    "for type_of_input in input_types:\n",
    "    # In the next two lines, we are initializing X and y\n",
    "    tf_input['X'][type_of_input]=tf.placeholder(tf.float32,[hyper_parameters['batch_size'],hyper_parameters['max_sequence_length'],hyper_parameters['number_input_in_each_instant'][type_of_input]])\n",
    "    tf_input['y'][type_of_input]=tf.placeholder(tf.float32,[hyper_parameters['batch_size'],hyper_parameters['softmax_probability']])\n",
    "    # Building block of gru\n",
    "    gru_cells[type_of_input]=[tf.contrib.rnn.GRUCell(number_of_the_rnn_cells,name=type_of_input+\"_gru\") for x in range(number_of_layers_in_rnns)]\n",
    "    # Densed rnn cell using MultiRNNCell\n",
    "    densed_gru_cells[type_of_input]=tf.contrib.rnn.MultiRNNCell(gru_cells[type_of_input])\n",
    "    # Next funcion will help you to synthesize \n",
    "    raw_time_outputs[type_of_input]=tf.nn.dynamic_rnn(densed_gru_cells[type_of_input],tf_input['X'][type_of_input],dtype=tf.float32)[0]\n",
    "    # This function will reduce any output except for those which we have discussed\n",
    "    last_time_instant[type_of_input]=tf.transpose(raw_time_outputs[type_of_input],[1,0,2])[-1]\n",
    "    # function for deal_learning\n",
    "    deep_layer[type_of_input]=get_deep_layer(type_of_input)\n",
    "    # functoin for output synthesizing\n",
    "    output_layer[type_of_input]=get_output_from_deep(type_of_input)\n",
    "    different_costs[type_of_input]=tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf_input['y'][type_of_input],logits=deep_layer[type_of_input])\n",
    "total_cost=sum([different_costs[type_of_input] for type_of_input in input_types])\n",
    "# total_cost=different_costs['coarse']+different_costs['']\n",
    "optimizer=tf.train.AdamOptimizer().minimize(total_cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1245,
     "status": "ok",
     "timestamp": 1528986151728,
     "user": {
      "displayName": "Karan Dhingra",
      "photoUrl": "//lh6.googleusercontent.com/-5rw5kj6_qp4/AAAAAAAAAAI/AAAAAAAALMA/vP4yaQCADJA/s50-c-k-no/photo.jpg",
      "userId": "112729077975125827597"
     },
     "user_tz": -330
    },
    "id": "zZp7nuzga0aq",
    "outputId": "ec62e18b-12f3-4622-90ba-f8dd6054716a"
   },
   "outputs": [],
   "source": [
    "# defining interactive session for ease of usage\n",
    "tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KCngHv_5a0av"
   },
   "outputs": [],
   "source": [
    "# Initializing global variables\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "colab_type": "code",
    "id": "hdbm1lcGa0az",
    "outputId": "92ffcdf1-d243-4ae5-8268-4f6486fd1930",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This array maintains cost function.\n",
    "cost_output=[]\n",
    "# for how many a steps, rnn whould run\n",
    "number_of_steps=1500\n",
    "for e in tqdm(range(number_of_steps)):\n",
    "    # starting_index ise used to randomly select starting point for better generalization\n",
    "    starting_index=np.random.randint(hyper_parameters['length_of_wave']-hyper_parameters['max_sequence_length']-2)\n",
    "    \n",
    "    # Intialization\n",
    "    X_coarse=[]\n",
    "    y_coarse=[]\n",
    "    X_fine=[]\n",
    "    y_fine=[]\n",
    "    \n",
    "    #One hot encoding for y\n",
    "    encoding_array=np.zeros(hyper_parameters['softmax_probability'])\n",
    "    encoding_array[y['coarse'][starting_index+hyper_parameters['max_sequence_length']-1]]=1\n",
    "    \n",
    "    # Appended coarse based output on X\n",
    "    X_coarse.append(np.asarray(X['coarse'][starting_index:starting_index+hyper_parameters['max_sequence_length']]).reshape(hyper_parameters['max_sequence_length'],2))\n",
    "    \n",
    "    # Appended y as one hot encoding\n",
    "    y_coarse.append(encoding_array)\n",
    "    encoding_array=np.zeros(hyper_parameters['softmax_probability'])\n",
    "    encoding_array[y['fine'][starting_index+hyper_parameters['max_sequence_length']-1]]=1\n",
    "    \n",
    "    # Same intialization as with X_coarse\n",
    "    X_fine.append(np.asarray(X['fine'][starting_index:starting_index+hyper_parameters['max_sequence_length']]).reshape(hyper_parameters['max_sequence_length'],3))\n",
    "    # Same initialization\n",
    "    y_fine.append(encoding_array)\n",
    "    \n",
    "    # Optimizing the whole architecture\n",
    "    optimizer.run(feed_dict={tf_input['X']['coarse']:X_coarse,tf_input['y']['coarse']:y_coarse,tf_input['y']['fine']:y_fine,tf_input['X']['fine']:X_fine})\n",
    "\n",
    "    # Keeping track of learning curve by logging down cost\n",
    "    if e %(number_of_steps/10):\n",
    "        cost_in_turn=total_cost.eval(feed_dict={tf_input['X']['coarse']:X_coarse,tf_input['y']['coarse']:y_coarse,tf_input['y']['fine']:y_fine,tf_input['X']['fine']:X_fine})\n",
    "        cost_output.append(cost_in_turn) \n",
    "\n",
    "# plotting the cost\n",
    "plt.plot(cost_output)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 640
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2401,
     "status": "ok",
     "timestamp": 1528986095325,
     "user": {
      "displayName": "Karan Dhingra",
      "photoUrl": "//lh6.googleusercontent.com/-5rw5kj6_qp4/AAAAAAAAAAI/AAAAAAAALMA/vP4yaQCADJA/s50-c-k-no/photo.jpg",
      "userId": "112729077975125827597"
     },
     "user_tz": -330
    },
    "id": "9xHU1joLa0a8",
    "outputId": "26e04071-cd12-4a66-a334-be325335cc02"
   },
   "outputs": [],
   "source": [
    "# Random index for better prediction\n",
    "starting_index=np.random.randint(hyper_parameters['length_of_wave']-hyper_parameters['max_sequence_length']-2)\n",
    "\n",
    "# data initializtion\n",
    "X_coarse=list(X['coarse'][starting_index:starting_index+hyper_parameters['max_sequence_length']])\n",
    "X_fine=list(X['fine'][starting_index:starting_index+hyper_parameters['max_sequence_length']])\n",
    "# intializing arrays to manage plots between both outputs\n",
    "coarse_plot=list([e[0] for e in X_coarse])\n",
    "fine_plot=list([e[2] for e in X_fine])\n",
    "\n",
    "for printer in range(hyper_parameters['new_sequences']):\n",
    "    \n",
    "    # predicting values based on previous\n",
    "    coarse_out=output_layer['coarse'].eval(feed_dict={tf_input['X']['coarse']:np.asarray(X_coarse[printer:]).reshape((hyper_parameters['batch_size'],hyper_parameters['max_sequence_length'],hyper_parameters['number_input_in_each_instant']['coarse']))})\n",
    "    fine_out=output_layer['fine'].eval(feed_dict={tf_input['X']['fine']:np.asarray(X_fine[printer:]).reshape((hyper_parameters['batch_size'],hyper_parameters['max_sequence_length'],hyper_parameters['number_input_in_each_instant']['fine']))})\n",
    "    \n",
    "    # Appending predicted values to the input sequence\n",
    "    X_coarse.append([X_fine[-1][2],fine_plot[-1]])\n",
    "    X_fine.append([X_fine[-1][2],fine_plot[-1],coarse_out])\n",
    "    coarse_plot.append(coarse_out)\n",
    "    fine_plot.append(fine_out)\n",
    "\n",
    "plt.plot(coarse_plot,label=\"Coarse\")\n",
    "plt.plot(fine_plot,label=\"fine\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of the model,\n",
    "\n",
    "### please go through some of the issues I have mentioned in the repository\n",
    "\n",
    "\n",
    "As I did find many a things interesting while going through it and tested the model on those things too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "default_view": {},
   "name": "Untitled.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
